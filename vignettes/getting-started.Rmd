---
title: "getting-started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{getting-started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment  = "#>",
  fig.width = 6, fig.height = 4,
  message = FALSE, warning = FALSE
)

# Optional dependencies used in visualization sections
has_rpart      <- requireNamespace("rpart", quietly = TRUE)
has_rpartplot  <- requireNamespace("rpart.plot", quietly = TRUE)

```

## Overview

This vignette introduces the main functionality of the ROOT package through a simple end-to-end example.

- simulate data with `get_data()`,
- compute cross-fitted pseudo-outcomes with `estimate_dml()`,
- learn a single weighted tree via `tree_opt()`,
- build a weighted forest via `forest_opt()` and obtain a voting classifier.

**Columns used below**

- Outcome: `Yobs`  
- Treatment: `Tr`  
- Sample indicator: `S`


```{r}
library(ROOT)
```

## Simulate data

```{r}
set.seed(599)
sim <- get_data(n = 2000, seed = 599)

D <- sim$data      # columns: X0:...:X9, Yobs, S, Tr
Y <- sim$Y         # columns: Y0, Y1

# True PATE in the target sample S == 0
true_pate <- mean(Y$Y1[D$S == 0]) - mean(Y$Y0[D$S == 0])
true_pate
```

## Cross-fitted pseudo-outcomes (DML)

```{r}
dml <- estimate_dml(
  data     = D,
  outcome  = "Yobs",
  treatment= "Tr",
  sample   = "S",
  crossfit = 5
)

# Peek at the first few rows
head(dml$df_v, 10)

# Estimated PATE (mean of pseudo treatment effects)
mean(dml$df_v$te)
```

# Single weighted tree

```{r}
tr_res <- tree_opt(
  data       = D,
  outcome    = "Yobs",
  treatment  = "Tr",
  sample     = "S",
  leaf_proba = 0.25,
  seed       = 599
)

# How many are included/excluded by the learned policy?
table(tr_res$D$w, useNA = "ifany")

# Visualize the learned classifier (requires rpart + rpart.plot)
library(rpart.plot)

rpart.plot::rpart.plot(
  tr_res$f,
  type = 2,              # split labels below the node
  extra = 109,           # class + prob + % obs
  under = TRUE,          # put text under the node
  faclen = 0,            # don't abbreviate factor levels
  tweak = 1.1,           # slightly larger text
  fallen.leaves = TRUE,  # leaves at bottom
  shadow.col = "gray",   # drop shadow
  box.palette = "RdBu",  # color palette for classes
  branch.lty = 3,        # dashed branches
  main = "Weighted Tree Classifier"
)
```

## Weighted forest and Rashomon voting

```{r}
fo_res <- forest_opt(
  data          = D,
  outcome       = "Yobs",
  treatment     = "Tr",
  sample        = "S",
  leaf_proba    = 0.25,
  seed          = 3,
  num_trees     = 50,
  vote_threshold= 2/3,
  explore_proba = 0.05,
  feature_est   = "Ridge",
  top_k_trees   = FALSE,
  cutoff        = "baseline"
)

# How many trees are kept in the Rashomon set?
length(fo_res$rashomon_set)

# Plot the final characterized tree, if available
if (!is.null(fo_res$f)) {
  rpart.plot::rpart.plot(
    fo_res$f,
    type = 2,
    extra = 109,
    under = TRUE,
    faclen = 0,
    tweak = 1.1,
    fallen.leaves = TRUE,
    shadow.col = "gray",
    box.palette = "RdBu",
    branch.lty = 3,
    main = "Final Characterized Tree from Rashomon Set"
  )
}

```
