% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/core_functions.R
\name{tree_opt}
\alias{tree_opt}
\title{Fit a single weighted tree for optimized subgroup selection}
\usage{
tree_opt(
  data,
  outcome,
  treatment,
  sample,
  leaf_proba = 0.25,
  seed = NULL,
  verbose = FALSE
)
}
\arguments{
\item{data}{A data frame containing the full dataset (must include outcome, treatment, and sample columns).}

\item{outcome}{Name of the outcome column.}

\item{treatment}{Name of the treatment indicator column (0/1).}

\item{sample}{Name of the sample indicator column (0/1).}

\item{leaf_proba}{Numeric in \verb{[0,1]}, the probability weight assigned to choosing a "leaf" (no split) at each node during tree building (default 0.25).}

\item{seed}{Integer seed for reproducibility (default 42). A single \code{set.seed} is called at the start for all random components.}

\item{verbose}{Logical, if \code{TRUE} enables verbose logging of the tree-building process (prints details of splits and decisions). Defaults to \code{FALSE}.}
}
\value{
A list with components:
\item{D}{A data frame (same rows as \code{data2}) including covariates and additional columns:
\code{v} (pseudo-outcome), \code{vsq} (squared pseudo-outcome), \code{w} (optimized weight, 0/1), and \code{S} (sample indicator).}
\item{f}{An \code{rpart} model fit on \code{X} vs \code{w} (the classifier summarizing the learned weights).}
\item{testing_data}{A data frame of the subset of \code{data} used in tree optimization (specifically, those with \code{S==1} and finite weights). This is essentially the \code{data2} from the DML step.}
}
\description{
Runs a Double ML procedure to compute pseudo-outcomes, then grows a single decision tree that optimizes an objective function (approximate treatment effect standard error) by reweighting observations. Finally, fits a shallow classifier to summarize the resulting weights.
}
\details{
\strong{Procedure:} First, cross-fitted pseudo-outcomes are computed using \code{\link{estimate_dml}} (with a default of 5 folds). Then a ridge regression (or GBM, if specified) is used to estimate feature importances for \code{vsq} (the variance of the pseudo-outcome), which informs the initial feature selection probabilities. A special "leaf" option is included with probability \code{leaf_proba} to allow the tree to terminate splits. The function then calls an internal recursive splitting routine to assign binary weights \code{w} to observations, optimizing the treatment effect estimate's precision. The final classifier (\code{f}) is a decision tree of fixed depth (by default 3) trained on \code{X} to predict the optimized \code{w} labels for interpretability.

\strong{Randomness and Reproducibility:} The function uses random number generation in the tree-building process (for tie-breaking and exploration). Setting the same \code{seed} will produce the same result. The \code{verbose} flag can be used to trace the splitting process for debugging or insight.
}
\examples{
 sim<-get_data(n=2000,seed=599)
 D <-sim$data
 dml<-estimate_dml(D,outcome="Yobs",treatment="Tr",sample="S",crossfit= 5)
 tr_res <- forest_opt(D,
                  outcome="Yobs",treatment="Tr",sample="S",
                  leaf_proba=0.25,seed=599)
}
